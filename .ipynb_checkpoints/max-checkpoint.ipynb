{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übung 3 - Merkmalsextraktion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Maximilian Weber, **Matr.-Nr.:** 560245\n",
    "<br>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bearbeitungszeitraum\n",
    "\n",
    "**Bearbeitungsbegin:** Mo, 19.12.2019\n",
    "<br>\n",
    "**Abgabe:** So, 30.01.2020, 23:55 Uhr\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabenbeschreibung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ziel dieser Übung ist es, den prinzipiellen Ablauf einer Bildanalyse (inkl. einzelne Teilschritte) auf ein Bild anzuwenden und somit auch den Zusammenhang einzelner Operationen besser nachzuvollziehen.\n",
    "\n",
    "![AblaufBildanalyse](AblaufBildanalyse.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Generelle Hinweise zur Bearbeitung: \n",
    "\n",
    "Die Herausforderung hierbei ist, dass mehrere Phasen der Bildverarbeitung aufeinander aufbauend umgesetzt werden müssen. Zudem ist die Planung sowie die Durchführung des Lösungsweges (ohne konkrete Vorgaben) Ihnen überlassen. Jedoch sollten Sie folgende allgemeine und hilfreiche \"Werkzeuge\" ins Betracht ziehen:\n",
    "\n",
    "**Phasen der Bildverarbeitung:**\n",
    "1.\tBild öffnen\n",
    "2.\tBildvorverarbeitung\n",
    "3.\tSegmentierung\n",
    "4.\tObjekterkennung\n",
    "5.\tAnalyse\n",
    "6.\tVisualisierung\n",
    "\n",
    "**Zur Segmentierung:**\n",
    "1.\tIterative Berechnung des optimalen Schwellenwertes\n",
    "2.\tHistogrammanalyse für multimodale Histogramme\n",
    "\n",
    "**Zur Objekterkennung**\n",
    "1.\tAlgorithmus zur Detektion von Kreisen\n",
    "2.\tHough-Transformation\n",
    "3.\tSkelettierung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Hinweise zur Abgabe und zur Benotung\n",
    "\n",
    "- Füllen Sie unbedingt die erste Zelle unterhalb der Überschrift mit Name und Matr.-Nr. aus!\n",
    "- Ergänzen Sie den Dateinamen des Notebooks vor der Abgabe um `_` und Ihre Matr.-Nr. (`Uebung 1 - Biosignale_s0500000_s0500001.ipynb`).\n",
    "- Entfernen Sie vor dem Upload alle Ausgaben aus dem Notebook!\n",
    "- Die Bilddatei muss nicht abgegeben werden.\n",
    "- Die Aufgabe wird nach dem üblichen Notenschema von 1,0 bis 5,0 bewertet.\n",
    "- Diese Aufgabe wird mit 40% in der Gesamtnote der Übung gewichtet.\n",
    "\n",
    "### Viel Erfolg!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabenbeschreibung\n",
    "\n",
    "Lesen Sie `roentgen.tif` mit Hilfe der `matplotlib`-Bibliothek ein. Visualisieren Sie das, in der Datei enthaltene Bild (verwenden Sie die Funktionen `imshow` und `show`).\n",
    "\n",
    "1.\tBerechnen Sie die Anzahl der Finger im Bild.\n",
    "2.\tFinden Sie die Knochen und die Hand. Berechnen Sie dazu den Anteil der Knochen an der Gesamtfläche der Hand.\n",
    "3.\tBerechnen Sie die Anzahl gesamten (einzelnen) Knochen.\n",
    " \n",
    "**Bonus:** \n",
    "4. Berechnen Sie die zusätzlich zur Anzahl auch die maximale Länge jedes Knochens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import skimage\n",
    "from skimage import color\n",
    "from skimage import feature\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage import measure\n",
    "from skimage import morphology, segmentation\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.filters import sobel\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import canny\n",
    "from skimage.exposure import histogram\n",
    "from skimage import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f7be31f83d0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_original\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"gray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Original Image\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_original\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Conda\\envs\\552351\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2675\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2676\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[1;32m-> 2677\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2678\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2679\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Conda\\envs\\552351\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1597\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Conda\\envs\\552351\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Conda\\envs\\552351\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Conda\\envs\\552351\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5677\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5679\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5680\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5681\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Conda\\envs\\552351\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    683\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[0;32m    684\u001b[0m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[1;32m--> 685\u001b[1;33m                             \"float\".format(self._A.dtype))\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m         if not (self._A.ndim == 2\n",
      "\u001b[1;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Bildaufnahme\n",
    "#######################################################\n",
    "\n",
    "img_original = cv2.imread(\"roentgen.tif\", 0)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.subplot(1,2,1),plt.imshow(img_original, \"gray\")\n",
    "plt.title(\"Original Image\")\n",
    "plt.subplot(1,2,2),plt.hist(img_original.ravel(), bins=np.linspace(0, 255, 255))\n",
    "plt.title(\"Histogramm\")\n",
    "plt.show()\n",
    "\n",
    "print(type(img_original))\n",
    "print(img_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Bildvorverarbeitung Filtering\n",
    "\n",
    "#######################################################\n",
    "\n",
    "import scipy\n",
    "#result = filters.thresholding.try_all_threshold(img_med_blur)\n",
    "\n",
    "\n",
    "img_med_blur = cv2.medianBlur(img_original,9)\n",
    "\n",
    "#img_med_blur = scipy.ndimage.median_filter(img_original, size=3)\n",
    "\n",
    "\n",
    "\n",
    "image_background = img_med_blur.copy()\n",
    "\n",
    "for i in range(image_background.shape[0]):\n",
    "    for j in range(image_background.shape[1]):\n",
    "        if image_background[i,j] < 90:\n",
    "            image_background[i,j] = 0\n",
    "            \n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(2,2,1),plt.imshow(image_background, \"gray\")\n",
    "plt.title(\"Image background filtered\")\n",
    "plt.subplot(2,2,2),plt.hist(image_background.ravel(), bins=np.linspace(0, 255, 255))\n",
    "plt.ylim(0,10000)\n",
    "plt.title(\"Histogramm\")\n",
    "plt.subplot(2,2,3),plt.imshow(img_med_blur, \"gray\")\n",
    "plt.title(\"Image median filtered\")\n",
    "plt.subplot(2,2,4),plt.hist(img_med_blur.ravel(), bins=np.linspace(0, 255, 255))\n",
    "plt.ylim(0,10000)\n",
    "plt.title(\"Histogramm\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Bildvorverarbeitung Threshhold + morphologisch\n",
    "#######################################################\n",
    "\n",
    "\n",
    "img_binary = cv2.adaptiveThreshold(img_med_blur,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "           cv2.THRESH_BINARY,11,2)\n",
    "\n",
    "\n",
    "#ret, img_binary = cv2.threshold(img_med_blur,0,255,cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#FAIZ THRESH\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "block_size = 55\n",
    "adaptive_thresh = threshold_local(img_med_blur, block_size, offset=5)\n",
    "binary_adaptive = img_med_blur > adaptive_thresh\n",
    "\n",
    "\n",
    "#OPENING CLOSING\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "img_closing = cv2.morphologyEx(img_binary, cv2.MORPH_CLOSE, kernel, iterations = 1)\n",
    "img_opening = cv2.morphologyEx(img_binary, cv2.MORPH_OPEN, kernel, iterations = 1)\n",
    "image_erosion = cv2.erode(img_binary, kernel, iterations = 1)\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.subplot(1,2,1),plt.imshow(img_binary, \"gray\")\n",
    "plt.title(\"binary + med blur\")\n",
    "plt.subplot(1,2,2),plt.imshow(img_opening, \"gray\")\n",
    "plt.title(\"Erosion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3. Segmentierung\n",
    "#######################################################\n",
    "\n",
    "coins = image_erosion\n",
    "\n",
    "edges = feature.canny(coins, sigma = 1000)\n",
    "\n",
    "fill_coins = ndi.binary_fill_holes(edges)\n",
    "\n",
    "label_objects, nb_labels = ndi.label(fill_coins)\n",
    "sizes = np.bincount(label_objects.ravel())\n",
    "mask_sizes = sizes > 10\n",
    "mask_sizes[0] = 0\n",
    "coins_cleaned = mask_sizes[label_objects]\n",
    "\n",
    "markers = np.zeros_like(coins)\n",
    "\n",
    "elevation_map = sobel(coins)\n",
    "\n",
    "markers = np.zeros_like(coins)\n",
    "markers[coins < 100] = 1\n",
    "markers[coins > 150 ] = 2\n",
    "#markers[coins > 130] = 3\n",
    "\n",
    "segments = watershed(elevation_map, markers, compactness = 1000)\n",
    "\n",
    "segments = ndi.binary_fill_holes(segments-1)\n",
    "\n",
    "labeled_coins, _ = ndi.label(segments)\n",
    "image_label_overlay = color.label2rgb(labeled_coins, image=coins)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.subplot(1,2,1),plt.imshow(image_label_overlay)\n",
    "plt.title(\"Image Segmentation, colored\")\n",
    "plt.subplot(1,2,2),plt.imshow(segments, \"gray\")\n",
    "plt.title(\"Image Segmentation\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(image_erosion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 3. Segmentierung (Nachbearbeitung)\n",
    "#####################################################################\n",
    "\n",
    "def count_values(np_arr, value):\n",
    "    counter = 0\n",
    "    for x in range(np_arr.shape[0]):\n",
    "        for y in range(np_arr.shape[1]):\n",
    "            if(np_arr[x,y] == value):\n",
    "                counter += 1\n",
    "    return counter\n",
    "\n",
    "\n",
    "print(np.amax(labeled_coins))\n",
    "\n",
    "show_array = np.zeros_like(coins)\n",
    "show_array[markers != 2] = 1\n",
    "\n",
    "\n",
    "\n",
    "min_marker_size = 5000 #pixels\n",
    "for x in range(np.amax(labeled_coins)):\n",
    "    print(x)\n",
    "    print(count_values(labeled_coins, x))\n",
    "    show_array = np.zeros_like(coins)\n",
    "    show_array[labeled_coins != x] = 1\n",
    "    plt.imshow(show_array, \"gray\")\n",
    "    plt.show()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3. Segmentierung -- Canny + Watershed + Kmeans\n",
    "#######################################################\n",
    "\n",
    "img_to_seg = img_med_blur\n",
    "\n",
    "edges = skimage.feature.canny(img_to_seg, sigma = 0.5)\n",
    "\n",
    "dt = distance_transform_edt(~edges)\n",
    "\n",
    "local_max = feature.peak_local_max(dt, indices=False, min_distance = 20)\n",
    "\n",
    "markers = measure.label(local_max)\n",
    "\n",
    "labels = morphology.watershed(-dt, markers)\n",
    "\n",
    "regions = measure.regionprops(labels, intensity_image = img_to_seg)\n",
    "region_means = [r.mean_intensity for r in regions]\n",
    "\n",
    "model = KMeans(n_clusters=2)\n",
    "region_means = np.array(region_means).reshape(-1,1)\n",
    "\n",
    "model.fit(region_means)\n",
    "\n",
    "bg_fg_labels = model.predict(region_means)\n",
    "classified_labels = labels.copy()\n",
    "for(bg_fg, region) in zip(bg_fg_labels, regions):\n",
    "    classified_labels[tuple(region.coords.T)] = bg_fg\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(2,3,1),plt.imshow(edges)\n",
    "plt.title(\"Canny Filter for Edges\")\n",
    "plt.subplot(2,3,2),plt.imshow(dt)\n",
    "plt.title(\"Image to Landscape\")\n",
    "plt.subplot(2,3,3),plt.imshow(segmentation.mark_boundaries(img_to_seg, labels))\n",
    "plt.title(\"Watershed\")\n",
    "plt.subplot(2,3,4),plt.imshow(color.label2rgb(labels, image = img_to_seg))\n",
    "plt.title(\"Segmented in colors\")\n",
    "plt.subplot(2,3,5),plt.imshow(color.label2rgb(labels, image = img_to_seg, kind = \"avg\"), cmap = \"gray\")\n",
    "plt.title(\"Segmented with average grayscale\")\n",
    "plt.subplot(2,3,6),plt.imshow(color.label2rgb(classified_labels, image = img_to_seg))\n",
    "plt.title(\"Greaycale k-meaned\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Segmentierung Convert Kmeans Image\n",
    "#######################################################\n",
    "labels_morm = color.label2rgb(classified_labels, image = img_to_seg)\n",
    "\n",
    "labels_morm = color.label2rgb(labels, image = img_to_seg, kind = \"avg\")\n",
    "ret, img_binary = cv2.threshold(labels_morm,0,255,cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Segmentierung CV Watershed\n",
    "#######################################################\n",
    "\n",
    "img_to_seg = img_binary\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "# sure background area\n",
    "sure_bg = cv2.dilate(img_to_seg, kernel, iterations=3)\n",
    "\n",
    "# Finding sure foreground area\n",
    "dist_transform = cv2.distanceTransform(img_to_seg,cv2.DIST_L2,5)\n",
    "ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "\n",
    "# Finding unknown region\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "# Marker labelling\n",
    "ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(2,3,1),plt.imshow(img_to_seg)\n",
    "plt.title(\"Image to Segment\")\n",
    "plt.subplot(2,3,2),plt.imshow(sure_bg)\n",
    "plt.title(\"Sure Background\")\n",
    "plt.subplot(2,3,3),plt.imshow(sure_fg)\n",
    "plt.title(\"Sure Foreground\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Bildvorverarbeitung -- Opening and Closing and Threshhold\n",
    "#######################################################\n",
    "\n",
    "#OPENING CLOSING\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "img_closing = cv2.morphologyEx(img_binary, cv2.MORPH_CLOSE, kernel, iterations = 1)\n",
    "img_erosion = cv2.erode(img_binary, kernel, iterations = 10)\n",
    "img_opening = cv2.morphologyEx(img_binary, cv2.MORPH_OPEN, kernel, iterations = 1)\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.subplot(1,2,1),plt.imshow(img_binary, \"gray\")\n",
    "plt.title(\"Binary\")\n",
    "plt.subplot(1,2,2),plt.imshow(img_erosion, \"gray\")\n",
    "plt.title(\"verarbeitet\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 4. Objekterkennung -- Labeling image regions\n",
    "#######################################################\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from skimage import data\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, square\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "cleared = img_erosion\n",
    "\n",
    "# label image regions\n",
    "label_image = label(cleared)\n",
    "image_label_overlay = label2rgb(label_image, image=img_original)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.imshow(image_label_overlay)\n",
    "\n",
    "for region in regionprops(label_image):\n",
    "    # take regions with large enough areas\n",
    "    if region.area >= 1:\n",
    "        # draw rectangle around segmented coins\n",
    "        minr, minc, maxr, maxc = region.bbox\n",
    "        rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                                  fill=False, edgecolor='red', linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. TRASH\n",
    "#######################################################\n",
    "\n",
    "#img = cv2.equalizeHist(img_original)\n",
    "\n",
    "blockSize = 3\n",
    "Constant = 3\n",
    "#thresh_img = cv2.adaptiveThreshold(img_original, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, blockSize, Constant)\n",
    "\n",
    "\n",
    "ret, thresh_img = cv2.threshold(img_original, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU) \n",
    "\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "img_closing = cv2.morphologyEx(img_original, cv2.MORPH_CLOSE, kernel, iterations = 5)\n",
    "img_opening = cv2.morphologyEx(img_original, cv2.MORPH_OPEN, kernel, iterations = 5)\n",
    "\n",
    "#############\n",
    "image_slic = seg.slic(img_med_blur, n_segments = 200)\n",
    "\n",
    "image_felzenszwalb = seg.felzenszwalb(img_med_blur) \n",
    "###############\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(2,2,1),plt.imshow(img_original, \"gray\")\n",
    "plt.title(\"Original\")\n",
    "plt.subplot(2,2,2),plt.imshow(img_closing, \"gray\")\n",
    "plt.title(\"test\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Achtung:\n",
    "\n",
    "1. Die Lösung soll gelten für:\n",
    "    - beliebig große Bilder (Zeilen- und Spaltenanzahl)\n",
    "    - andere Bilder als das Testbild (z.B. `Testbild_Roentgen2.jpg`), jedoch in demselben Bildtyp (Grau- oder Farbbild) und mit derselben Art von Objekten\n",
    "    - Objekte an beliebiger Stelle im Bild (auch Objekte an Rändern und Ecken können vorkommen!). „Unvollständige“ Objekte müssen allerdings nicht berücksichtigt werden. Also berücksichtigen Sie bitte, anders als in den Übungen, auch die Sonderfälle. \n",
    "    \n",
    "\n",
    "2. Der Quellcode wird für die Benotung auch an anderen Bildern als diesen Testbildern getestet!\n",
    "\n",
    "\n",
    "3. Bewertet werden:\n",
    "    - Das Ergebnis (Anzahl gefundener Objekte, Ergebnis der Analysen, etc.)\n",
    "    - Der Lösungsweg (Programmaufbau, Geschwindigkeit, benutzte Algorithmen)\n",
    "    - Fehlerresistenz und Allgemeingültigkeit (Test mit anderen Bildern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
